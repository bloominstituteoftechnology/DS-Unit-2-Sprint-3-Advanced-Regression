{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ayDccRP01GJD"
   },
   "source": [
    "# Data Science Unit 2 Sprint Challenge 3\n",
    "\n",
    "## Logistic Regression and Beyond\n",
    "\n",
    "In this sprint challenge you will fit a logistic regression modeling the probability of an adult having an income above 50K. The dataset is available at UCI:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/adult\n",
    "\n",
    "Your goal is to:\n",
    "\n",
    "1. Load, validate, and clean/prepare the data.\n",
    "2. Fit a logistic regression model\n",
    "3. Answer questions based on the results (as well as a few extra questions about the other modules)\n",
    "\n",
    "Don't let the perfect be the enemy of the good! Manage your time, and make sure to get to all parts. If you get stuck wrestling with the data, simplify it (if necessary, drop features or rows) so you're able to move on. If you have time at the end, you can go back and try to fix/improve.\n",
    "\n",
    "### Hints\n",
    "\n",
    "It has a variety of features - some are continuous, but many are categorical. You may find [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) (a method to one-hot encode) helpful!\n",
    "\n",
    "The features have dramatically different ranges. You may find [sklearn.preprocessing.minmax_scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.minmax_scale.html#sklearn.preprocessing.minmax_scale) helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U22R1Ud51hxb"
   },
   "source": [
    "## Part 1 - Load, validate, and prepare data\n",
    "\n",
    "The data is available at: https://archive.ics.uci.edu/ml/datasets/adult\n",
    "\n",
    "Load it, name the columns, and make sure that you've loaded the data successfully. Note that missing values for categorical variables can essentially be considered another category (\"unknown\"), and may not need to be dropped.\n",
    "\n",
    "You should also prepare the data for logistic regression - one-hot encode categorical features as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SeOByIkht-NS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                  1      2           3   4                    5   \\\n",
       "0  39          State-gov  77516   Bachelors  13        Never-married   \n",
       "1  50   Self-emp-not-inc  83311   Bachelors  13   Married-civ-spouse   \n",
       "\n",
       "                 6               7       8      9     10  11  12  \\\n",
       "0      Adm-clerical   Not-in-family   White   Male  2174   0  40   \n",
       "1   Exec-managerial         Husband   White   Male     0   0  13   \n",
       "\n",
       "               13      14  \n",
       "0   United-States   <=50K  \n",
       "1   United-States   <=50K  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load pandas, data.csv and create column names\n",
    "import pandas as pd\n",
    "\n",
    "names1 = ['age', 'working_class','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','fifty_k']\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=None )\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>working_class</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>fifty_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age working_class  fnlwgt   education  education-num  marital-status  \\\n",
       "0   39     State-gov   77516   Bachelors             13   Never-married   \n",
       "\n",
       "      occupation    relationship    race    sex  capital-gain  capital-loss  \\\n",
       "0   Adm-clerical   Not-in-family   White   Male          2174             0   \n",
       "\n",
       "   hours-per-week  native-country fifty_k  \n",
       "0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "df.columns = names1\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode all categorical data\n",
    "obj_df = df.select_dtypes(include=['object']).copy()\n",
    "df_encoded = pd.get_dummies(df, columns=list(obj_df), drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>working_class_ Federal-gov</th>\n",
       "      <th>working_class_ Local-gov</th>\n",
       "      <th>working_class_ Never-worked</th>\n",
       "      <th>working_class_ Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "      <th>fifty_k_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   working_class_ Federal-gov  working_class_ Local-gov  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "\n",
       "   working_class_ Never-worked  working_class_ Private      ...        \\\n",
       "0                            0                       0      ...         \n",
       "1                            0                       0      ...         \n",
       "2                            0                       1      ...         \n",
       "3                            0                       1      ...         \n",
       "4                            0                       1      ...         \n",
       "\n",
       "   native-country_ Puerto-Rico  native-country_ Scotland  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                      0                       0                         0   \n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                                0                              1   \n",
       "1                                0                              1   \n",
       "2                                0                              1   \n",
       "3                                0                              1   \n",
       "4                                0                              0   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  fifty_k_ >50K  \n",
       "0                        0                           0              0  \n",
       "1                        0                           0              0  \n",
       "2                        0                           0              0  \n",
       "3                        0                           0              0  \n",
       "4                        0                           0              0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "df_encoded['fifty_k_ >50K'].plot.bar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RT1LFnFO1lo6"
   },
   "source": [
    "## Part 2 - Fit and present a Logistic Regression\n",
    "\n",
    "Your data should now be in a state to fit a logistic regression. Use scikit-learn, define your `X` (independent variable) and `y`, and fit a model.\n",
    "\n",
    "Then, present results - display coefficients in as interpretible a way as you can (hint - scaling the numeric features will help, as it will at least make coefficients more comparable to each other). If you find it helpful for interpretation, you can also generate predictions for cases (like our 5 year old rich kid on the Titanic) or make visualizations - but the goal is your exploration to be able to answer the question, not any particular plot (i.e. don't worry about polishing it).\n",
    "\n",
    "It is *optional* to use `train_test_split` or validate your model more generally - that is not the core focus for this week. So, it is suggested you focus on fitting a model first, and if you have time at the end you can do further validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate data into features and target, and train and test\n",
    "#Scaling has not been performed on this first attempt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df_encoded.loc[:,'age':'native-country_ Yugoslavia']\n",
    "y = df_encoded.loc[:,'fifty_k_ >50K']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7972420994441203"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run regression and see score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "log_reg = log.fit(X_train, y_train)\n",
    "log_reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7fTRDXguD7N"
   },
   "outputs": [],
   "source": [
    "#Set predictions variable\n",
    "predictions = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8026242322724735"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check predictions score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "\n",
      "age :  -0.004331431056283785\n",
      "fnlwgt :  -3.5276733136160007e-06\n",
      "education-num :  -0.002174801676520017\n",
      "capital-gain :  0.00034435383011747664\n",
      "capital-loss :  0.0007885400757040971\n",
      "hours-per-week :  -0.01097542148279274\n",
      "working_class_ Federal-gov :  0.0001401706797506627\n",
      "working_class_ Local-gov :  5.607824273266792e-05\n",
      "working_class_ Never-worked :  -3.0388381189261e-06\n",
      "working_class_ Private :  -0.001769400155056068\n",
      "working_class_ Self-emp-inc :  0.0003502722764794547\n",
      "working_class_ Self-emp-not-inc :  -1.6225602938440587e-05\n",
      "working_class_ State-gov :  -9.59779678008305e-07\n",
      "working_class_ Without-pay :  -3.7059648254401763e-06\n",
      "education_ 11th :  -0.0003747270328781491\n",
      "education_ 12th :  -0.00011866654458144316\n",
      "education_ 1st-4th :  -4.7688923418212265e-05\n",
      "education_ 5th-6th :  -8.873340015383073e-05\n",
      "education_ 7th-8th :  -0.00018398198409642845\n",
      "education_ 9th :  -0.00014275647065825918\n",
      "education_ Assoc-acdm :  -5.099898594286039e-05\n",
      "education_ Assoc-voc :  -2.1704995374512795e-05\n",
      "education_ Bachelors :  0.0009606893744558886\n",
      "education_ Doctorate :  0.00025431230391428786\n",
      "education_ HS-grad :  -0.00164477396522746\n",
      "education_ Masters :  0.0005648437503738191\n",
      "education_ Preschool :  -1.797982308664288e-05\n",
      "education_ Prof-school :  0.000276172216578956\n",
      "education_ Some-college :  -0.0008182178721854413\n",
      "marital-status_ Married-AF-spouse :  5.2609817459646285e-06\n",
      "marital-status_ Married-civ-spouse :  0.0034889485939618003\n",
      "marital-status_ Married-spouse-absent :  -0.00010506723447706164\n",
      "marital-status_ Never-married :  -0.003471477492772549\n",
      "marital-status_ Separated :  -0.0002848850194279912\n",
      "marital-status_ Widowed :  -0.00028064819682808637\n",
      "occupation_ Adm-clerical :  -0.0007318489462204615\n",
      "occupation_ Armed-Forces :  -2.2783329641275577e-06\n",
      "occupation_ Craft-repair :  -0.00021920485833487775\n",
      "occupation_ Exec-managerial :  0.0010407857688163114\n",
      "occupation_ Farming-fishing :  -0.0002602844185062364\n",
      "occupation_ Handlers-cleaners :  -0.00038134183526843476\n",
      "occupation_ Machine-op-inspct :  -0.0003782476976958162\n",
      "occupation_ Other-service :  -0.0010491175909227628\n",
      "occupation_ Priv-house-serv :  -4.7961740081920054e-05\n",
      "occupation_ Prof-specialty :  0.0008522271598937697\n",
      "occupation_ Protective-serv :  6.112146813538564e-05\n",
      "occupation_ Sales :  -3.374356431620849e-05\n",
      "occupation_ Tech-support :  6.816945362536401e-05\n",
      "occupation_ Transport-moving :  -0.0001620451696951808\n",
      "relationship_ Not-in-family :  -0.002061358619284339\n",
      "relationship_ Other-relative :  -0.0003033028229808606\n",
      "relationship_ Own-child :  -0.001870269005438228\n",
      "relationship_ Unmarried :  -0.0010139041070273977\n",
      "relationship_ Wife :  0.0004250545753572734\n",
      "race_ Asian-Pac-Islander :  -5.36099741540496e-05\n",
      "race_ Black :  -0.0005379166497796784\n",
      "race_ Other :  -7.769282394700054e-05\n",
      "race_ White :  -0.0009367764861190934\n",
      "sex_ Male :  0.0008551452109452706\n",
      "native-country_ Cambodia :  1.4814079828030663e-06\n",
      "native-country_ Canada :  2.4452969385749357e-06\n",
      "native-country_ China :  6.752945523041633e-06\n",
      "native-country_ Columbia :  -1.5515380284569537e-05\n",
      "native-country_ Cuba :  1.2373566735012853e-05\n",
      "native-country_ Dominican-Republic :  -2.4408338628491778e-05\n",
      "native-country_ Ecuador :  -2.406142801223841e-06\n",
      "native-country_ El-Salvador :  -2.5983600886891028e-05\n",
      "native-country_ England :  1.2434729835443962e-05\n",
      "native-country_ France :  7.677908320932039e-06\n",
      "native-country_ Germany :  -1.2857850209935914e-06\n",
      "native-country_ Greece :  -3.5259877332711036e-06\n",
      "native-country_ Guatemala :  -1.48008592570539e-05\n",
      "native-country_ Haiti :  -5.168922186733302e-06\n",
      "native-country_ Holand-Netherlands :  -1.7233715300044621e-06\n",
      "native-country_ Honduras :  -3.250543074034243e-06\n",
      "native-country_ Hong :  -1.710821039655761e-06\n",
      "native-country_ Hungary :  -2.314189616984161e-06\n",
      "native-country_ India :  2.0296003266789427e-05\n",
      "native-country_ Iran :  5.11895008683729e-06\n",
      "native-country_ Ireland :  -8.740852399117615e-07\n",
      "native-country_ Italy :  8.153244971190454e-06\n",
      "native-country_ Jamaica :  -1.306961470284505e-05\n",
      "native-country_ Japan :  5.7842173470554035e-06\n",
      "native-country_ Laos :  -6.206535724513534e-06\n",
      "native-country_ Mexico :  -0.00013251848983906897\n",
      "native-country_ Nicaragua :  -8.758055915627036e-06\n",
      "native-country_ Outlying-US(Guam-USVI-etc) :  -5.4571590509435595e-06\n",
      "native-country_ Peru :  -4.35159589992452e-06\n",
      "native-country_ Philippines :  5.779811985749474e-06\n",
      "native-country_ Poland :  -1.0010457504247054e-05\n",
      "native-country_ Portugal :  -8.258592182298747e-06\n",
      "native-country_ Puerto-Rico :  -2.144008260537846e-05\n",
      "native-country_ Scotland :  7.273725596318682e-07\n",
      "native-country_ South :  -1.1847033689601315e-05\n",
      "native-country_ Taiwan :  1.0627066000838097e-05\n",
      "native-country_ Thailand :  -8.860217015797279e-07\n",
      "native-country_ Trinadad&Tobago :  -4.67501147060872e-06\n",
      "native-country_ United-States :  -0.0014314664855198346\n",
      "native-country_ Vietnam :  -2.1694159601445208e-05\n",
      "native-country_ Yugoslavia :  1.575335438990699e-07\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-aaf711941e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Coefficients:\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "#Print coefficients for all variables without scaling\n",
    "print('Coefficients:\\n')\n",
    "for i in range(len(df_encoded)):\n",
    "    print(list(df_encoded)[i], ': ', log.coef_[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64 were all converted to float64.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Scale data for next attempt at logistic regression\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "df_encoded[['age','fnlwgt','capital-gain','capital-loss','hours-per-week']] = minmax_scale(df_encoded[['age','fnlwgt','capital-gain','capital-loss','hours-per-week']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate data again\n",
    "X = df_encoded.loc[:,'age':'native-country_ Yugoslavia']\n",
    "y = df_encoded.loc[:,'fifty_k_ >50K']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8504038573753877"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run logistic regression\n",
    "log = LogisticRegression()\n",
    "log_reg = log.fit(X_train, y_train)\n",
    "log_reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set predictions\n",
    "predictions = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496184626837893"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check accuracy of predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients after min_max scaling: \n",
      "\n",
      "age :  1.9441693007692153\n",
      "fnlwgt :  1.0983267623162127\n",
      "education-num :  0.14656629458160425\n",
      "capital-gain :  16.288223159811785\n",
      "capital-loss :  2.4645217461806657\n",
      "hours-per-week :  2.7285412856987548\n",
      "working_class_ Federal-gov :  0.8053279345903519\n",
      "working_class_ Local-gov :  0.17819004488175175\n",
      "working_class_ Never-worked :  -0.13811454456106279\n",
      "working_class_ Private :  0.35909288410431384\n",
      "working_class_ Self-emp-inc :  0.5628829087394709\n",
      "working_class_ Self-emp-not-inc :  -0.11131522079921767\n",
      "working_class_ State-gov :  0.09400118931510996\n",
      "working_class_ Without-pay :  -0.45933499865428684\n",
      "education_ 11th :  -0.34695414059217144\n",
      "education_ 12th :  -0.07914888059605861\n",
      "education_ 1st-4th :  -0.368496503730575\n",
      "education_ 5th-6th :  -0.09056333414136558\n",
      "education_ 7th-8th :  -0.4135484456009051\n",
      "education_ 9th :  -0.3001855090515108\n",
      "education_ Assoc-acdm :  0.12990564927140633\n",
      "education_ Assoc-voc :  0.36915453183043717\n",
      "education_ Bachelors :  0.6459963691222855\n",
      "education_ Doctorate :  1.2714739826094723\n",
      "education_ HS-grad :  0.060327448069360946\n",
      "education_ Masters :  0.8118967877521434\n",
      "education_ Preschool :  -0.8267072191648115\n",
      "education_ Prof-school :  1.1334704408661669\n",
      "education_ Some-college :  0.2789322279886354\n",
      "marital-status_ Married-AF-spouse :  1.5138491525235402\n",
      "marital-status_ Married-civ-spouse :  1.2793422433929773\n",
      "marital-status_ Married-spouse-absent :  -0.17590149482370632\n",
      "marital-status_ Never-married :  -0.5419821788314289\n",
      "marital-status_ Separated :  -0.16705599936133247\n",
      "marital-status_ Widowed :  -0.1539509620386489\n",
      "occupation_ Adm-clerical :  0.27713266256583186\n",
      "occupation_ Armed-Forces :  -0.2943738896140846\n",
      "occupation_ Craft-repair :  0.32789059994739184\n",
      "occupation_ Exec-managerial :  0.9928188419869955\n",
      "occupation_ Farming-fishing :  -0.8885342912452983\n",
      "occupation_ Handlers-cleaners :  -0.37496363918993625\n",
      "occupation_ Machine-op-inspct :  -0.04605641751403195\n",
      "occupation_ Other-service :  -0.5154629736411399\n",
      "occupation_ Priv-house-serv :  -1.0765967628569217\n",
      "occupation_ Prof-specialty :  0.7381979690219331\n",
      "occupation_ Protective-serv :  0.725281340603265\n",
      "occupation_ Sales :  0.5452392625809768\n",
      "occupation_ Tech-support :  0.9415418822035949\n",
      "occupation_ Transport-moving :  0.0767301573328859\n",
      "relationship_ Not-in-family :  -0.2797003400410499\n",
      "relationship_ Other-relative :  -0.9553749890474964\n",
      "relationship_ Own-child :  -1.1273295460471733\n",
      "relationship_ Unmarried :  -0.5408750445991496\n",
      "relationship_ Wife :  1.2197204911783988\n",
      "race_ Asian-Pac-Islander :  0.05531921049475694\n",
      "race_ Black :  -0.012170114660081844\n",
      "race_ Other :  -0.23544776531099237\n",
      "race_ White :  0.19795324543602696\n",
      "sex_ Male :  0.7228953228287407\n",
      "native-country_ Cambodia :  1.0018877896084075\n",
      "native-country_ Canada :  0.23698428012051914\n",
      "native-country_ China :  -0.07745856821824251\n",
      "native-country_ Columbia :  -1.128671370154242\n",
      "native-country_ Cuba :  0.4807428343932169\n",
      "native-country_ Dominican-Republic :  -0.8800469871607011\n",
      "native-country_ Ecuador :  -0.03311572127889761\n",
      "native-country_ El-Salvador :  -0.3392182571570069\n",
      "native-country_ England :  0.7158825237863687\n",
      "native-country_ France :  0.5863136329302555\n",
      "native-country_ Germany :  0.2336751789018261\n",
      "native-country_ Greece :  -0.6447022314439329\n",
      "native-country_ Guatemala :  0.19276760785956998\n",
      "native-country_ Haiti :  0.15595991905140216\n",
      "native-country_ Holand-Netherlands :  -0.01837412591525873\n",
      "native-country_ Honduras :  -0.2305623071179982\n",
      "native-country_ Hong :  -0.26097407060675604\n",
      "native-country_ Hungary :  -0.2735907264327125\n",
      "native-country_ India :  0.01062737564574056\n",
      "native-country_ Iran :  -0.010303855621217033\n",
      "native-country_ Ireland :  0.5829287179362345\n",
      "native-country_ Italy :  0.6159855163135508\n",
      "native-country_ Jamaica :  0.3169138755196336\n",
      "native-country_ Japan :  0.37984149806705075\n",
      "native-country_ Laos :  -0.700419568160699\n",
      "native-country_ Mexico :  -0.42425722325446324\n",
      "native-country_ Nicaragua :  -0.9510068740707724\n",
      "native-country_ Outlying-US(Guam-USVI-etc) :  -0.6657476576878805\n",
      "native-country_ Peru :  -0.06776213511061127\n",
      "native-country_ Philippines :  0.38030713216221357\n",
      "native-country_ Poland :  -0.2310818268580487\n",
      "native-country_ Portugal :  0.2140148030659603\n",
      "native-country_ Puerto-Rico :  -0.08924798177292652\n",
      "native-country_ Scotland :  0.10886147849822608\n",
      "native-country_ South :  -0.4274487989629242\n",
      "native-country_ Taiwan :  0.06832265528246377\n",
      "native-country_ Thailand :  -0.11265305637263923\n",
      "native-country_ Trinadad&Tobago :  -0.2683520206919159\n",
      "native-country_ United-States :  0.24830665531698168\n",
      "native-country_ Vietnam :  -0.43178509643460106\n",
      "native-country_ Yugoslavia :  0.027378435440039175\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-2cc19b993e51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Coefficients after min_max scaling: \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "#Print new coefficients\n",
    "print('Coefficients after min_max scaling: \\n')\n",
    "for i in range(len(df_encoded)):\n",
    "    print(list(df_encoded)[i], ': ', log.coef_[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BkIa-Sa21qdC"
   },
   "source": [
    "## Part 3 - Analysis, Interpretation, and Questions\n",
    "\n",
    "### Based on your above model, answer the following questions\n",
    "\n",
    "1. What are 3 features positively correlated with income above 50k?\n",
    "2. What are 3 features negatively correlated with income above 50k?\n",
    "3. Overall, how well does the model explain the data and what insights do you derive from it?\n",
    "\n",
    "*These answers count* - that is, make sure to spend some time on them, connecting to your analysis above. There is no single right answer, but as long as you support your reasoning with evidence you are on the right track.\n",
    "\n",
    "Note - scikit-learn logistic regression does *not* automatically perform a hypothesis test on coefficients. That is OK - if you scale the data they are more comparable in weight.\n",
    "\n",
    "---\n",
    "### Peyton's Answers\n",
    "1. wife, age, and having a doctorate are possitively correlated with income above 50k\n",
    "\n",
    "2. own child, other-relative, and native_country_ Laos are all negatively correlated with income above 50k\n",
    "\n",
    "3. This model does a solid job of explaining the data. The score, which functions similarly to R^2, is about .85 for the test data. This is indicative of fairly strong explanatory power. Before deriving too many \"insights\" from the data, an initial sanity check can be performed by looking at variables that are commonly known to predict increased income, such as higher education and having a wife. Both of these are correct. Some insights that may be drawn from the data (greater and lower incomes is in reference to fifty k):\n",
    "\n",
    "\n",
    "    Which countries are associated with greater and lower incomes \n",
    "    \n",
    "    Which categories of jobs are associated with greater and lower incomes \n",
    "    \n",
    "    Which relationship statuses are associated with greater and lower incomes\n",
    "    \n",
    "    The relationship between race and incomes\n",
    "    \n",
    "    The relationship between sex and incomes\n",
    "    \n",
    "    The relationship between number of hours worked per week and income\n",
    "    \n",
    "You can also compare the impact of different factors by comparing the magnitude of their coefficients, but this could also be a reach without further exploration and processing of the data. \n",
    "\n",
    "---\n",
    "\n",
    "### Match the following situation descriptions with the model most appropriate to addressing them\n",
    "\n",
    "In addition to logistic regression, a number of other approaches were covered this week. Pair them with the situations they are most appropriate for, and briefly explain why.\n",
    "\n",
    "Situations:\n",
    "\n",
    "---\n",
    "1. You are given data on academic performance of primary school students, and asked to fit a model to help predict \"at-risk\" students who are likely to receive the bottom tier of grades.\n",
    "\n",
    "### Answer\n",
    "\n",
    "Quantile Regression: I don't actually think that quantile regression is appropriate here. It's just not appropriate anywhere else. Quantile regression could tell you in which way the features impact the lowest performers, but not predict which observations will be low performers. Quantile regression might be more appropriate for designing an intervention (e.g. we see that the coefficient on feature X is quite large for our lowest performers, so lets design an intervention based around X). \n",
    "\n",
    "---\n",
    "  \n",
    "  \n",
    "---\n",
    "2. You are studying tech companies and their patterns in releasing new products, and would like to be able to model and predict when a new product is likely to be launched.\n",
    "\n",
    "### Answer\n",
    "\n",
    "Survival Analysis: this tool is used when modeling time to an event. In this case, the event is a product launch. \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "3. You are working on modeling expected plant size and yield with a laboratory that is able to capture fantastically detailed physical data about plants, but only of a few dozen plants at a time.\n",
    "\n",
    "### Answer\n",
    "\n",
    "Ridge Regression: this tool is appropriate for regularizing data that suffers from having too many features given the total number of observations. Fantastically detailed physical information likely means many static features, while the total number of observations is quite limited.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Approaches:\n",
    "1. Ridge Regression\n",
    "2. Quantile Regression\n",
    "3. Survival Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yjj0sseiuHib"
   },
   "source": [
    "**TODO - your answers!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DS_Unit_2_Sprint_Challenge_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
